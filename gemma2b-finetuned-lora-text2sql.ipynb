{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65502d65",
   "metadata": {
    "papermill": {
     "duration": 0.006535,
     "end_time": "2024-02-24T16:15:04.737948",
     "exception": false,
     "start_time": "2024-02-24T16:15:04.731413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-tune Gemma for Text to SQL in Keras using LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1e14a",
   "metadata": {
    "papermill": {
     "duration": 0.005581,
     "end_time": "2024-02-24T16:15:04.749488",
     "exception": false,
     "start_time": "2024-02-24T16:15:04.743907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook demonstrates how to fine-tune Gemma-2B to answer with SQL query as output given an input consitent of a question in plain English and a schmea of a table — in other words, the model will convert a question we ask in natural language like the following:\n",
    "\n",
    "```\n",
    "“How many customers did buy Camembert in the month of August?”\n",
    "```\n",
    "\n",
    "And given a schema of the table that looks like this:\n",
    "```sql\n",
    "CREATE TABLE purchases (\n",
    "    purchase_id INT PRIMARY KEY,\n",
    "    purchase_date DATE,\n",
    "    customer_id INT,\n",
    "    product_name VARCHAR(128)\n",
    ");\n",
    "```\n",
    "\n",
    "Into a SQL query that can be run on the `purchases` table to get the actual result:\n",
    "```sql\n",
    "SELECT COUNT(DISTINCT customer_id) AS num_customers\n",
    "FROM purchases\n",
    "WHERE product_name = 'camembert'\n",
    "AND EXTRACT(MONTH FROM purchase_date) = 8;\n",
    "```\n",
    "\n",
    "We will be using this [Text to SQL Dataset](https://huggingface.co/datasets/knowrohit07/know_sql) in the tuning process.\n",
    "\n",
    "> Note: Whilst this notebook shows primarily how to fine-tune for the Text to SQL task, the approach can be easily adapted the tuning Gemma-2B for other tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffa341b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:15:04.763239Z",
     "iopub.status.busy": "2024-02-24T16:15:04.762403Z",
     "iopub.status.idle": "2024-02-24T16:15:05.567136Z",
     "shell.execute_reply": "2024-02-24T16:15:05.566316Z"
    },
    "papermill": {
     "duration": 0.814224,
     "end_time": "2024-02-24T16:15:05.569565",
     "exception": false,
     "start_time": "2024-02-24T16:15:04.755341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189be25a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:15:05.583435Z",
     "iopub.status.busy": "2024-02-24T16:15:05.582994Z",
     "iopub.status.idle": "2024-02-24T16:15:05.587331Z",
     "shell.execute_reply": "2024-02-24T16:15:05.586529Z"
    },
    "papermill": {
     "duration": 0.013279,
     "end_time": "2024-02-24T16:15:05.589157",
     "exception": false,
     "start_time": "2024-02-24T16:15:05.575878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a9b109f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:15:05.601807Z",
     "iopub.status.busy": "2024-02-24T16:15:05.601542Z",
     "iopub.status.idle": "2024-02-24T16:15:05.605232Z",
     "shell.execute_reply": "2024-02-24T16:15:05.604482Z"
    },
    "papermill": {
     "duration": 0.012082,
     "end_time": "2024-02-24T16:15:05.607055",
     "exception": false,
     "start_time": "2024-02-24T16:15:05.594973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "006cf461",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:15:05.620775Z",
     "iopub.status.busy": "2024-02-24T16:15:05.620514Z",
     "iopub.status.idle": "2024-02-24T16:15:05.631488Z",
     "shell.execute_reply": "2024-02-24T16:15:05.630293Z"
    },
    "papermill": {
     "duration": 0.020339,
     "end_time": "2024-02-24T16:15:05.633355",
     "exception": false,
     "start_time": "2024-02-24T16:15:05.613016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/gemma/keras/gemma_2b_en/2/config.json\n",
      "/kaggle/input/gemma/keras/gemma_2b_en/2/tokenizer.json\n",
      "/kaggle/input/gemma/keras/gemma_2b_en/2/metadata.json\n",
      "/kaggle/input/gemma/keras/gemma_2b_en/2/model.weights.h5\n",
      "/kaggle/input/gemma/keras/gemma_2b_en/2/assets/tokenizer/vocabulary.spm\n",
      "/kaggle/input/inputs/know_sql_val3ign.json\n",
      "/kaggle/input/data-assistants-with-gemma/submission_categories.txt\n",
      "/kaggle/input/data-assistants-with-gemma/submission_instructions.txt\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6456f7bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:15:05.646249Z",
     "iopub.status.busy": "2024-02-24T16:15:05.645997Z",
     "iopub.status.idle": "2024-02-24T16:15:34.142757Z",
     "shell.execute_reply": "2024-02-24T16:15:34.141506Z"
    },
    "papermill": {
     "duration": 28.506205,
     "end_time": "2024-02-24T16:15:34.145519",
     "exception": false,
     "start_time": "2024-02-24T16:15:05.639314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\r\n",
      "tensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U keras-nlp\n",
    "!pip install -q -U keras>=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67024b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:15:34.161264Z",
     "iopub.status.busy": "2024-02-24T16:15:34.160920Z",
     "iopub.status.idle": "2024-02-24T16:15:34.166077Z",
     "shell.execute_reply": "2024-02-24T16:15:34.165268Z"
    },
    "papermill": {
     "duration": 0.01536,
     "end_time": "2024-02-24T16:15:34.168090",
     "exception": false,
     "start_time": "2024-02-24T16:15:34.152730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n",
    "# Avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f52f16d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:15:34.182740Z",
     "iopub.status.busy": "2024-02-24T16:15:34.182410Z",
     "iopub.status.idle": "2024-02-24T16:15:47.425174Z",
     "shell.execute_reply": "2024-02-24T16:15:47.424401Z"
    },
    "papermill": {
     "duration": 13.252551,
     "end_time": "2024-02-24T16:15:47.427470",
     "exception": false,
     "start_time": "2024-02-24T16:15:34.174919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 16:15:38.127399: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-24 16:15:38.127534: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-24 16:15:38.272198: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a40fac",
   "metadata": {
    "papermill": {
     "duration": 0.005889,
     "end_time": "2024-02-24T16:15:47.440817",
     "exception": false,
     "start_time": "2024-02-24T16:15:47.434928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> Add model from right hand side by add model button and add `gemma_2b_en` Model (9.34 GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fec67c12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:15:47.454630Z",
     "iopub.status.busy": "2024-02-24T16:15:47.454084Z",
     "iopub.status.idle": "2024-02-24T16:16:49.012592Z",
     "shell.execute_reply": "2024-02-24T16:16:49.011731Z"
    },
    "papermill": {
     "duration": 61.568013,
     "end_time": "2024-02-24T16:16:49.014941",
     "exception": false,
     "start_time": "2024-02-24T16:15:47.446928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ed833b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:16:49.036212Z",
     "iopub.status.busy": "2024-02-24T16:16:49.035868Z",
     "iopub.status.idle": "2024-02-24T16:17:01.170284Z",
     "shell.execute_reply": "2024-02-24T16:17:01.169069Z"
    },
    "papermill": {
     "duration": 12.146651,
     "end_time": "2024-02-24T16:17:01.172663",
     "exception": false,
     "start_time": "2024-02-24T16:16:49.026012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.4)\r\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2023.12.2)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf7b3c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:17:01.191820Z",
     "iopub.status.busy": "2024-02-24T16:17:01.190863Z",
     "iopub.status.idle": "2024-02-24T16:17:01.644721Z",
     "shell.execute_reply": "2024-02-24T16:17:01.643630Z"
    },
    "papermill": {
     "duration": 0.465919,
     "end_time": "2024-02-24T16:17:01.647297",
     "exception": false,
     "start_time": "2024-02-24T16:17:01.181378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read JSON file into a DataFrame\n",
    "df = pd.read_json('/kaggle/input/inputs/know_sql_val3ign.json')\n",
    "\n",
    "# Write the DataFrame to a Parquet file\n",
    "df.to_parquet('output.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "574388e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:17:01.666671Z",
     "iopub.status.busy": "2024-02-24T16:17:01.666325Z",
     "iopub.status.idle": "2024-02-24T16:17:01.791525Z",
     "shell.execute_reply": "2024-02-24T16:17:01.790517Z"
    },
    "papermill": {
     "duration": 0.137526,
     "end_time": "2024-02-24T16:17:01.793931",
     "exception": false,
     "start_time": "2024-02-24T16:17:01.656405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_df = pd.read_parquet(\"output.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4809808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:17:01.812144Z",
     "iopub.status.busy": "2024-02-24T16:17:01.811627Z",
     "iopub.status.idle": "2024-02-24T16:17:01.824856Z",
     "shell.execute_reply": "2024-02-24T16:17:01.823983Z"
    },
    "papermill": {
     "duration": 0.024347,
     "end_time": "2024-02-24T16:17:01.826801",
     "exception": false,
     "start_time": "2024-02-24T16:17:01.802454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how many district with incumbent being lindy boggs</td>\n",
       "      <td>CREATE TABLE table_1341586_19 (district VARCHAR, incumbent VARCHAR)</td>\n",
       "      <td>SELECT COUNT(district) FROM table_1341586_19 WHERE incumbent = \"Lindy Boggs\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what's the result with candidates being billy tauzin (d) unopposed</td>\n",
       "      <td>CREATE TABLE table_1341586_19 (result VARCHAR, candidates VARCHAR)</td>\n",
       "      <td>SELECT result FROM table_1341586_19 WHERE candidates = \"Billy Tauzin (D) Unopposed\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how many candidates with result being retired to run for u. s. senate republican hold</td>\n",
       "      <td>CREATE TABLE table_1341586_19 (candidates VARCHAR, result VARCHAR)</td>\n",
       "      <td>SELECT COUNT(candidates) FROM table_1341586_19 WHERE result = \"Retired to run for U. S. Senate Republican hold\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what's the result with district being louisiana 2</td>\n",
       "      <td>CREATE TABLE table_1341586_19 (result VARCHAR, district VARCHAR)</td>\n",
       "      <td>SELECT result FROM table_1341586_19 WHERE district = \"Louisiana 2\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who is the the candidates with first elected being 1977</td>\n",
       "      <td>CREATE TABLE table_1341586_19 (candidates VARCHAR, first_elected VARCHAR)</td>\n",
       "      <td>SELECT candidates FROM table_1341586_19 WHERE first_elected = 1977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 question  \\\n",
       "0                                      how many district with incumbent being lindy boggs   \n",
       "1                      what's the result with candidates being billy tauzin (d) unopposed   \n",
       "2   how many candidates with result being retired to run for u. s. senate republican hold   \n",
       "3                                       what's the result with district being louisiana 2   \n",
       "4                                 who is the the candidates with first elected being 1977   \n",
       "\n",
       "                                                                     context  \\\n",
       "0        CREATE TABLE table_1341586_19 (district VARCHAR, incumbent VARCHAR)   \n",
       "1         CREATE TABLE table_1341586_19 (result VARCHAR, candidates VARCHAR)   \n",
       "2         CREATE TABLE table_1341586_19 (candidates VARCHAR, result VARCHAR)   \n",
       "3           CREATE TABLE table_1341586_19 (result VARCHAR, district VARCHAR)   \n",
       "4  CREATE TABLE table_1341586_19 (candidates VARCHAR, first_elected VARCHAR)   \n",
       "\n",
       "                                                                                                            answer  \n",
       "0                                     SELECT COUNT(district) FROM table_1341586_19 WHERE incumbent = \"Lindy Boggs\"  \n",
       "1                              SELECT result FROM table_1341586_19 WHERE candidates = \"Billy Tauzin (D) Unopposed\"  \n",
       "2  SELECT COUNT(candidates) FROM table_1341586_19 WHERE result = \"Retired to run for U. S. Senate Republican hold\"  \n",
       "3                                               SELECT result FROM table_1341586_19 WHERE district = \"Louisiana 2\"  \n",
       "4                                               SELECT candidates FROM table_1341586_19 WHERE first_elected = 1977  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7316f033",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:17:01.845176Z",
     "iopub.status.busy": "2024-02-24T16:17:01.844467Z",
     "iopub.status.idle": "2024-02-24T16:17:01.849808Z",
     "shell.execute_reply": "2024-02-24T16:17:01.848970Z"
    },
    "papermill": {
     "duration": 0.016516,
     "end_time": "2024-02-24T16:17:01.851829",
     "exception": false,
     "start_time": "2024-02-24T16:17:01.835313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    return text.replace(u'\\xa0', u' ').strip()\n",
    "\n",
    "def prompt_fn(row):\n",
    "    template = \"Question:\\n{question}\\nContext:\\n{context}\\n\\nAnswer:\\n{answer}\"\n",
    "    prompt = template.format(\n",
    "      question=clean(row['question']), context=clean(row['context']), answer=clean(row['answer'])\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5af050b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:17:01.869774Z",
     "iopub.status.busy": "2024-02-24T16:17:01.869480Z",
     "iopub.status.idle": "2024-02-24T16:17:01.917884Z",
     "shell.execute_reply": "2024-02-24T16:17:01.916937Z"
    },
    "papermill": {
     "duration": 0.059317,
     "end_time": "2024-02-24T16:17:01.919733",
     "exception": false,
     "start_time": "2024-02-24T16:17:01.860416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "how many district with incumbent being lindy boggs\n",
      "Context:\n",
      "CREATE TABLE table_1341586_19 (district VARCHAR, incumbent VARCHAR)\n",
      "\n",
      "Answer:\n",
      "SELECT COUNT(district) FROM table_1341586_19 WHERE incumbent = \"Lindy Boggs\"\n"
     ]
    }
   ],
   "source": [
    "LIMIT = 2000\n",
    "data = raw_df[:LIMIT].apply(prompt_fn,axis=1).values.tolist()\n",
    "\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d91f1dc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:17:01.937717Z",
     "iopub.status.busy": "2024-02-24T16:17:01.937177Z",
     "iopub.status.idle": "2024-02-24T16:17:02.420097Z",
     "shell.execute_reply": "2024-02-24T16:17:02.419227Z"
    },
    "papermill": {
     "duration": 0.494073,
     "end_time": "2024-02-24T16:17:02.422218",
     "exception": false,
     "start_time": "2024-02-24T16:17:01.928145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,507,536,384\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,507,536,384\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,363,968</span> (5.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,363,968\u001b[0m (5.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enable LoRA for the model and set the LoRA rank to 4.\n",
    "gemma_lm.backbone.enable_lora(rank=4)\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c920b7a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:17:02.442743Z",
     "iopub.status.busy": "2024-02-24T16:17:02.442439Z",
     "iopub.status.idle": "2024-02-24T17:00:53.329239Z",
     "shell.execute_reply": "2024-02-24T17:00:53.328228Z"
    },
    "papermill": {
     "duration": 2630.899182,
     "end_time": "2024-02-24T17:00:53.331227",
     "exception": false,
     "start_time": "2024-02-24T16:17:02.432045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2629s\u001b[0m 1s/step - loss: 0.2184 - sparse_categorical_accuracy: 0.6938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7e683429fe50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the input sequence length to 512 (to control memory usage).\n",
    "gemma_lm.preprocessor.sequence_length = 512\n",
    "# Use AdamW (a common optimizer for transformer models).\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "# Exclude layernorm and bias terms from decay.\n",
    "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
    "\n",
    "gemma_lm.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=optimizer,\n",
    "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "gemma_lm.fit(data, epochs=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a715a20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T17:00:53.675448Z",
     "iopub.status.busy": "2024-02-24T17:00:53.674603Z",
     "iopub.status.idle": "2024-02-24T17:00:53.681146Z",
     "shell.execute_reply": "2024-02-24T17:00:53.680110Z"
    },
    "papermill": {
     "duration": 0.179674,
     "end_time": "2024-02-24T17:00:53.683068",
     "exception": false,
     "start_time": "2024-02-24T17:00:53.503394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What is the SFC when the specific impulse is 453?\n",
      "Context:\n",
      "CREATE TABLE table_15944_5 (sfc_in_g__kn·s_ VARCHAR, specific_impulse__s_ VARCHAR)\n",
      "\n",
      "Answer:\n",
      "SELECT sfc_in_g__kn·s_ FROM table_15944_5 WHERE specific_impulse__s_ = 453\n"
     ]
    }
   ],
   "source": [
    "print(prompt_fn(raw_df.loc[LIMIT]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b31858d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T17:00:54.019734Z",
     "iopub.status.busy": "2024-02-24T17:00:54.019292Z",
     "iopub.status.idle": "2024-02-24T17:01:25.587326Z",
     "shell.execute_reply": "2024-02-24T17:01:25.586367Z"
    },
    "papermill": {
     "duration": 31.912239,
     "end_time": "2024-02-24T17:01:25.763696",
     "exception": false,
     "start_time": "2024-02-24T17:00:53.851457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What kind of competition was it at San Siro at 18:30 GMT?\n",
      "Context:\n",
      "CREATE TABLE table_name_60 (competition VARCHAR, ground VARCHAR, time VARCHAR)\n",
      "\n",
      "Answer:\n",
      "SELECT competition FROM table_name_60 WHERE ground = \"San Siro\" AND time = \"18:30 GMT\"\n",
      "Expected: SELECT competition FROM table_name_60 WHERE ground = \"san siro\" AND time = \"18:30 gmt\"\n"
     ]
    }
   ],
   "source": [
    "row = {\n",
    "  \"question\": \"What kind of competition was it at San Siro at 18:30 GMT?\",\n",
    "  \"context\": \"CREATE TABLE table_name_60 (competition VARCHAR, ground VARCHAR, time VARCHAR)\",\n",
    "  \"answer\": \"\"\n",
    "}\n",
    "\n",
    "prompt = prompt_fn(row)\n",
    "print(gemma_lm.generate(prompt, max_length=256))\n",
    "print('Expected: SELECT competition FROM table_name_60 WHERE ground = \"san siro\" AND time = \"18:30 gmt\"')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7669720,
     "sourceId": 64148,
     "sourceType": "competition"
    },
    {
     "datasetId": 4479248,
     "sourceId": 7678172,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4489732,
     "sourceId": 7692894,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 5171,
     "sourceId": 11371,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2787.498586,
   "end_time": "2024-02-24T17:01:29.364902",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-24T16:15:01.866316",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
